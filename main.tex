\documentclass[11pt]{article}
\usepackage{url} % Allow URLs.
\usepackage{graphicx} % Allow inclusion of graphics.
\usepackage[sort&compress]{natbib} % Better bibliography handling.
\usepackage{geometry} % Sets page size and margins
\usepackage{authblk} % Put authors names in a block.
\usepackage{amsmath} % Allow fancy math stuff
\usepackage{amsfonts}
\usepackage{tabularx,ragged2e,booktabs} % Stuff for tables.
\usepackage{titlesec}
\usepackage{amssymb}
\usepackage{comment}
\usepackage{subcaption}
\usepackage{xcolor} % Allow colors.
\usepackage{hyperref}
\usepackage{amssymb}
\usepackage{dsfont}
\usepackage{float}
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{unicode-math}
\usepackage{algorithm}
\usepackage{algpseudocode}

\linespread{1.2}

% Use the short form for ISMB submission, long for biorxiv.
\newcommand{\shorten}[1]{#1}
\newcommand{\fixme}[2]{\color{red}{\bf #2 ---#1} \color{black}}
% Reduce the size of the affiliations
\renewcommand\Affilfont{\fontsize{9}{10.8}\itshape}
\DeclareMathOperator*{\argmax}{arg\,max\,\,}
\DeclareMathOperator*{\argmin}{arg\,min\,\,}

\title{GNN Interpretability Using Bayesian Inference}

\author[1,2]{Shalin Patel}

\affil[1]{Division of Applied Mathematics, Brown University}
\affil[2]{Department of Computer Science, Brown University}

\begin{document}

\begin{titlepage}
\begin{center}
	\vspace*{1cm}
	{\Large{\textbf{GNN Interpretability Using Bayesian Inference}}} \\
	\vspace{0.5cm}
	\textbf{Shalin Patel}
	\vfill
    
    Advisor: Dr. Ritambhara Singh \\
	Second Reader: Dr. Lorin Crawford \\
	\vspace{0.8cm}
	\includegraphics[width=0.4\textwidth]{images/brown} \\
    \vspace{0.8cm}
	Division of Applied Mathematics and Department of Computer Science\\
	Brown University\\
	2023-04-21
\end{center}
\end{titlepage}

\tableofcontents
\newpage

\maketitle
\begin{abstract}
GNNs have garnered a lot of attention as a flexible generalization of CNNs to operate on unstructured graphs of data. This has led to an explosion of different use cases as the general, unrestricted nature of graphs allow researchers to train models that integrate many different forms of related data under one framework. While CNNs and other deep learning methods have had a good amount of research done on model interpretability, GNNs are still in a nascent stage for interpretation. The goal of this work is to look at the state of GNN Interpretability and suggest some new benchmarks for testing interpretation methods as well as providing a Bayesian Inference based approach to the problem. It will be seen that the Bayesian Inference approach performs better than the state of the art in GNN Interpretability and provides for an introspectable tool to dissect GNNs for the benefit of researchers using the model type.
\end{abstract}

\input{1_intro}
\input{2_related}
\input{3_method}
\input{4_exp}
\input{5_results}
\input{6_discuss}

\bibliographystyle{unsrt}
\small{\bibliography{refs}}
\end{document}
