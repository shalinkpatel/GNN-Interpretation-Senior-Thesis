\section{Results}
Below the results from the experiments mentioned in \S\ref{sec:exp-setup} are outlined. Specifically, there are two main experiments that were run: the noise filtering experiment and the graph embedding dataset. As will be seen, the performance of both the Beta model and Normalizing Flow model exceeds that of GNNExplainer and provides additional information into the edge mask distribution. Note that in \cite{yuan_explainability_2021} and \cite{lin_generative_2021}, both GNNExplainer and PGExplainer demonstrate similar performance with their implementations coming from \cite{fey_fast_2019}. PGExplainer was unable to run on these examples with all predicted edge masks being very close to zero and demonstrating poor performance as a result. Hence, GNNExplainer is considered to be representative of the state of the art for the purposes of this work.

\subsection{Noise Filtering Experiment Results}
Note that for the following table, any prediction that was in the original graph structure is automatically given a correct. As mentioned before, since the goal of this experiment is not to determine the actual ground truth, but rather, to determine the ability of the explainer models to filter noise. For this experiment each of the methods was fed 25\% of the nodes that have noisy edges as a test and the results were collated. Not all nodes had noisy edges because of the probabilistic noise sampling mechanism, but on average 50\% of the edges were noisy. This methodology means that the interpretation methods were exposed to slightly greater than 50\% noise as all nodes with no noise were filtered out.

As can be seen from the results in table \ref{tab:noise-filter-res}, GNNExplainer underperforms compared to both the Beta Model and the Normalizing Flow Model. The results indicate that all methods are doing a decent job at ensuring that noise is not picked up as important to the model. While there is room for improvement across the board, all methods demonstrate favorable performance with the Bayesian learning methods leading the way in performance.
\begin{table}[htb] 
	\centering
	\begin{tabular}{|c||c|} \hline
	Model & Accuracy\\ \hline \hline
	GNNExplainer & 0.923\\ 
	Beta Explainer & \textbf{0.982}\\ 
	Normalizing Flow Explainer & 0.966\\ \hline
	\end{tabular}
	\caption{Accuracy results for all three models in the noise filtering experiment}
	\label{tab:noise-filter-res}
\end{table}

In particular, the Beta Model performs the best with the Normalizing Flow Model following it. While the Normalizing Flow Model is strictly more expressive than the Beta Model, it seems to exhibit higher variance in its training which leads to it picking up noise at times. This means that the Beta Model will perform better in experiments like this. Indeed, the restrictiveness of the Beta Model means that it would be more reluctant to pick any edge as positive. This probably explains its comparative advantage in this experiment and as will be shown later, the Beta Model is very good at picking out first-order pathways that are the most important to the GNN. While it may miss some information that is captured by the Normalizing Flow Model, this means that it is very good at filtering noise. 

The probabilistic approach to both the Beta Model and Normalizing Flow Model means that they are better suited for filtering noise as compared to GNNExplainer which experiences little penalty for picking up a noisy edge as it tends to have little effect on the performance of the GNN. Instead, GNNExplainer cares much more about finding the positive edges and has little incentive for dropping noisy edges as demonstrated in the GNN performance from figure \ref{fig:tree-model-sparsity} where the noisy edges added little value but did not decrease the performance of the model. In the probabilistic models, though, these edges add little value and are discarded due to their minimal effect on the model which is discovered when the edge is both sampled and not sampled. 

\subsection{Graph Embedding Experiment Results}
With a known and confirmed groundtruth in this experiment, the interpretation methods were run through a few different metrics: accuracy, precision, recall, f1 score, and AUROC. In this case, the interpretation methods were compared directly against the groundtruth and the results were averaged across nodes to get the final results as seen in table \ref{tab:graph-embed-result}. Additionally, the average of all explanation masks was taken in order to account for model variance and to get a sense of what a global interpretation score against the ground truth would give.
\begin{table}[htb]
	\centering
	\begin{tabular}{|c|c||ccccc|}\hline
	Model & Aggregation & Accuracy & Recall & Precision & F1 Score & AUROC \\ \hline\hline
	GNNExplainer & Avg Metrics & 0.612 & 0.599 & 0.386 & 0.468 & 0.601 \\
	Beta Explainer & Avg Metrics & \textbf{0.634} & 0.505 & \textbf{0.387} & 0.423 & \textbf{0.658} \\
	NF Explainer & Avg Metrics & 0.588 & \textbf{0.664} & 0.376 & \textbf{0.479} & 0.631 \\ \hline
	GNNExplainer & Avg Mask & 0.619 & 0.583 & 0.389 & 0.467 & 0.646 \\
	Beta Explainer & Avg Mask & \textbf{0.637} & 0.583 & \textbf{0.408} & 0.480 & \textbf{0.680} \\
	NF Explainer & Avg Mask & 0.595 & \textbf{0.667} & 0.381 & \textbf{0.485} & 0.669 \\ \hline
	\end{tabular} 
	\caption{A summary of results from the graph embedding experiment}
	\label{tab:graph-embed-result}
\end{table}

Based on these results, we can see that the Bayesian Inference interpretation methods are out-performing the current state-of-the-art in GNNExplainer. While the difference is not massive, these models perform better on all metrics and provide additional qualitative interpretation through the edge mask distributions that they generate. Specifically between the Beta Explainer and NF Explainer, the Beta Explainer has less recall but better precision which give it a higher accuracy and AUROC score while the better recall gives the NF Explainer a better F1 score. Overall, the NF Explainer has higher variance which leads to its lesser performance on the other metrics but the mean of its distribution tends to capture important edges a bit better than the Beta Explainer.

\subsubsection{Beta Model Edge Mask Distribution}
Additional, insights can be drawn about the GNN by looking at the distribution of edge mask values that the Beta Model came up with. In figure \ref{fig:tree-model-beta-marginal}, one can see the marginal distributions of edge mask values for each edge in the groundtruth. 
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.6\textwidth]{images/tree-model-beta-marginal.pdf}
	\caption{Marginal edge weight distributions of all groundtruth edges in the beta model for a particular training point}
	\label{fig:tree-model-beta-marginal}
\end{figure}
From these marginal distributions, it is clear that messages coming out and into node 1 are highly important and that flows from node 6 to 5 are also highly important. The rest of the edges are not considered important. Note that this is for this particular example and not in general. This makes sense, though as a concentration of density in node 5 would force the model to focus on that region. Since the variational posterior is quite inflexible, the analysis from this model can be quite confident but shallow as it will only highlight the most important pathways.

Furthermore, insights can be drawn by looking at the joint distribution between pairs of edges. This can give insight into what edges are correlated, anti-correlated, and how many modes there are to the edge mask distribution. This is important as it gives researchers insights into the different mechanisms that drive performance in the GNN. If the GNN is being used in a physical sciences or biology context, for example, this can help elucidate the various mechanisms that map to physical phenomenon. As seen in figure \ref{fig:tree-model-beta-joint}, the Beta Model helps provide a great first order approximation to these types of pathways.
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.6\textwidth]{images/tree-model-beta-joint.pdf}
	\caption{Joint edge weight distributions between pairs of groundtruth edges in the beta model for a particular training point}
	\label{fig:tree-model-beta-joint}
\end{figure}

Specifically, by looking at the joint distributions of edges, one can tell when a certain pair of edges is positively correlated, negatively correlated or lacks any correlation at all. In figure \ref{fig:tree-model-beta-joint}, looking at edges $3 \rightarrow 2$ and $1 \rightarrow 5$ demonstrates that for this example, the model is certain that edge $1 \rightarrow 5$ is important while the edge $3 \rightarrow 2$ is not. Perhaps this is due to an accumulation of density in node 5 while there was not as much sampled at node 2. Indeed, this can be corroborated by looking at $6 \rightarrow 5$ and $1 \rightarrow 5$ where both are very positively correlated and indicates that information is pooling at this node for this particular example. Finally, it is clear that bidirectional flows from node 1 and its neighbors are highly important as well. Overall, this gives a great unimodal intuition about the way in which information flows through the model.

\subsubsection{Normalizing Flow Model Edge Mask Distribution}
A similar analysis can be done for the Normalizing Flow Model. Note that this model is much more flexible than the Beta model which gives it a higher variance but allows it to capture multiple different pathways and local minima that the GNN may experience. This can already be seen in the marginal distributions as seen in figure \ref{fig:tree-model-dnfg-marginal}.
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.6\textwidth]{images/tree-model-dnfg-marginal.pdf}
	\caption{Marginal edge weight distributions for all groundtruth edges in the normalizing flow model for the same training point as \ref{fig:tree-model-beta-marginal}}
	\label{fig:tree-model-dnfg-marginal}
\end{figure}

Indeed, the same distributional shape as in the Beta Model can be seen, but the Normalizing Flow model learns many more modes in the distribution. Note that this corresponds to the various local minima in the training example which is useful as it indicates that are many different modes through which the GNN passes information around. This helps explain the Normalizing Flow Model's weaker performance compared to the Beta Model. The Beta Model can only pick out the most probable mode due to its relative inflexibility while the Normalizing Flow model picks up all the different peaks and troughs in the objective function giving it a higher variance but, essentially, correct overall distribution.

As with the Beta Model, the joint distribution between pairs of edges helps illustrate an even richer tale as seen in figure \ref{fig:tree-model-dnfg-joint}.
\begin{figure}[htb]
	\centering
	\includegraphics[width=0.6\textwidth]{images/tree-model-dnfg-joint.pdf}
	\caption{Joint edge weight distributions between pairs of groundtruth edges in the normalizing flow model for the same training point as \ref{fig:tree-model-beta-marginal}}
	\label{fig:tree-model-dnfg-joint}
\end{figure}

For example, we can now detect edge independence with edges $6 \rightarrow 5$ and $1 \rightarrow 2$ having little correlation with each other. If one were to condition on the modes of one of the edges, the conditional distribution could then indicate conditional pathways which clearly exist based on the multi-peaked joint distributions. While an example like this may not merit such analysis, in more complex datasets with graphs mapping to physical phenomenon, this could be of supreme importance and indicate all sorts of useful information.

\newpage
